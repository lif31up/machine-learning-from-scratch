{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-05T12:55:30.383114Z",
     "start_time": "2024-11-05T12:55:28.318797100Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "data = load_wine()\n",
    "shuffledIndices = np.random.permutation(len(data.target))\n",
    "data.data, data.target = data.data[shuffledIndices], data.target[shuffledIndices]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-05T12:55:30.395484400Z",
     "start_time": "2024-11-05T12:55:30.383114Z"
    }
   },
   "id": "31f32110ff50e2df"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# define Dataset\n",
    "class Dataset:\n",
    "    def __init__(self, dataset, vector_machine):\n",
    "      self.x, self.y = dataset\n",
    "      self.y = np.array([vector_machine[_] for _ in self.y])\n",
    "    def __getitem__(self, item): return self.x[item], self.y[item]\n",
    "    def __len__(self): return len(self.y)\n",
    "# Dataset\n",
    "\n",
    "def dataset_visualize(dataset: Dataset):\n",
    "  for x, y in dataset: print(f\"{'-' * 16}\\nx: {x}\\ny: {y}\")\n",
    "# dataset_visualize\n",
    "\n",
    "# init Datasets\n",
    "hv_machine = np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1]])\n",
    "trainset = Dataset((data.data, data.target), vector_machine=hv_machine)\n",
    "testset = Dataset((data.data, data.target), vector_machine=hv_machine)\n",
    "###dataset_visualize(trainset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-05T12:55:30.409046600Z",
     "start_time": "2024-11-05T12:55:30.396482900Z"
    }
   },
   "id": "39f312a34a31b709"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def sigmoid(x, e=2.7182): return 1 / (1 + e ** (-x))\n",
    "def relu(x): return np.array([max(0, _) for _ in x])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-05T12:55:30.409046600Z",
     "start_time": "2024-11-05T12:55:30.405986300Z"
    }
   },
   "id": "54a67165e172cf14"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def gradient(x, y, weight, act_func, lr):\n",
    "    indications = act_func(np.dot(x, weight))\n",
    "    return (lr / x.shape[0]) * (indications - y)\n",
    "# gradient\n",
    "\n",
    "class Node:\n",
    "    _next, _prev = None, None\n",
    "    def __init__(self, n_inpt, n_oupt, act_func=lambda x: x):\n",
    "        self.weight = np.random.rand(n_inpt, n_oupt)\n",
    "        self.act_func = act_func\n",
    "    # __init__\n",
    "\n",
    "    def __call__(self, x):\n",
    "        result = np.dot(x, self.weight)\n",
    "        self.output = result.copy()\n",
    "        self.grad = gradient(x, self.ouput, self.weight, act_func=self.act_func, lr=lr)\n",
    "        return result\n",
    "    # __call__\n",
    "    \n",
    "    def train(self, f, h, h_, lr):\n",
    "        f_ = gradient(h, f, self.weight, self.act_func, lr)\n",
    "        self.weight -= f_ * h_\n",
    "    # train\n",
    "    \n",
    "    def loss(self, dataset):\n",
    "        x, y = dataset.x, dataset.y\n",
    "        probability = np.dot(x, self.weight)\n",
    "        loss = np.mean(np.exp(1 - probability) * y) + np.sum(np.exp(probability) * (1 - y))\n",
    "        print(f\"cost: {loss:.3f}\")\n",
    "    # loss\n",
    "# Node"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-05T12:55:30.433676200Z",
     "start_time": "2024-11-05T12:55:30.415211800Z"
    }
   },
   "id": "dd08d93a44db92c0"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "class ANN:\n",
    "    def __init__(self):\n",
    "        prev, curr, first, attr = None, None, True, None\n",
    "        for attr_name in dir(self):\n",
    "            attr = getattr(self, attr_name)\n",
    "            if type(attr).__name__ == \"Node\" and attr_name != \"root\" and attr_name != \"tail\":\n",
    "                prev, curr = curr, attr\n",
    "                if first is True: self.root, first = curr, False\n",
    "                curr._prev = prev\n",
    "                if type(curr._prev).__name__ == \"Node\": curr._prev._next = curr\n",
    "        # for if if\n",
    "        self.tail = curr\n",
    "    # __init__\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        def propagate(curr, buffer_result):\n",
    "            if curr._next is None: return curr(buffer_result)\n",
    "            return propagate(curr._next, curr(buffer_result))\n",
    "        # propagate\n",
    "        return propagate(self.root, x)\n",
    "    # forward\n",
    "    \n",
    "    def train(self, dataset, iters: int, lr=0.01, act_func=relu):\n",
    "        def backpropagate(curr, x, y):\n",
    "            if curr._prev is None: # root\n",
    "                curr.train(x, curr.output)\n",
    "                return\n",
    "            if curr._next is None: # tail\n",
    "                curr.train(curr._prev.output, y)\n",
    "                return backpropagate(curr._prev, x, y)\n",
    "            curr.train(curr._prev.output, curr.output)\n",
    "            return backpropagate(curr._prev, x, y)\n",
    "        # backpropagation\n",
    "        for _ in range(iters):\n",
    "            for x, y in dataset:\n",
    "                self.__call__(x)\n",
    "                backpropagate(self.tail, x, y)\n",
    "        # for for\n",
    "    # train\n",
    "    \n",
    "    def loss(self, dataset):\n",
    "        x, y = dataset.x, dataset.y\n",
    "        probability = self.__call__(x)\n",
    "        loss = np.mean(np.exp(1 - probability) * y) + np.sum(np.exp(probability) * (1 - y))\n",
    "        print(f\"cost: {loss:.3f}\")\n",
    "    # loss\n",
    "# ANN"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-05T12:55:30.433676200Z",
     "start_time": "2024-11-05T12:55:30.423146800Z"
    }
   },
   "id": "90c96c0fea767241"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "class DNN(ANN):\n",
    "    def __init__(self, n_inpt, n_output):\n",
    "        self.l1 = Node(n_inpt, 2)\n",
    "        self.l2 = Node(2, 2, relu)\n",
    "        self.l3 = Node(2, n_output, sigmoid)\n",
    "        super().__init__()\n",
    "    # __init__\n",
    "# DNN"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-05T12:55:30.434685500Z",
     "start_time": "2024-11-05T12:55:30.428287Z"
    }
   },
   "id": "f40a04d02863821f"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Node' object has no attribute 'ouput'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[8], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m model \u001B[38;5;241m=\u001B[39m DNN(\u001B[38;5;28mlen\u001B[39m(trainset\u001B[38;5;241m.\u001B[39mx[\u001B[38;5;241m0\u001B[39m]), \u001B[38;5;28mlen\u001B[39m(trainset\u001B[38;5;241m.\u001B[39my[\u001B[38;5;241m0\u001B[39m]))\n\u001B[1;32m----> 2\u001B[0m model\u001B[38;5;241m.\u001B[39mloss(trainset)\n\u001B[0;32m      3\u001B[0m model\u001B[38;5;241m.\u001B[39mtrain(trainset, iters\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1000\u001B[39m, lr\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.01\u001B[39m)\n",
      "Cell \u001B[1;32mIn[6], line 43\u001B[0m, in \u001B[0;36mANN.loss\u001B[1;34m(self, dataset)\u001B[0m\n\u001B[0;32m     41\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mloss\u001B[39m(\u001B[38;5;28mself\u001B[39m, dataset):\n\u001B[0;32m     42\u001B[0m     x, y \u001B[38;5;241m=\u001B[39m dataset\u001B[38;5;241m.\u001B[39mx, dataset\u001B[38;5;241m.\u001B[39my\n\u001B[1;32m---> 43\u001B[0m     probability \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__call__\u001B[39m(x)\n\u001B[0;32m     44\u001B[0m     loss \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mmean(np\u001B[38;5;241m.\u001B[39mexp(\u001B[38;5;241m1\u001B[39m \u001B[38;5;241m-\u001B[39m probability) \u001B[38;5;241m*\u001B[39m y) \u001B[38;5;241m+\u001B[39m np\u001B[38;5;241m.\u001B[39msum(np\u001B[38;5;241m.\u001B[39mexp(probability) \u001B[38;5;241m*\u001B[39m (\u001B[38;5;241m1\u001B[39m \u001B[38;5;241m-\u001B[39m y))\n\u001B[0;32m     45\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcost: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mloss\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.3f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "Cell \u001B[1;32mIn[6], line 20\u001B[0m, in \u001B[0;36mANN.__call__\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m     18\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m propagate(curr\u001B[38;5;241m.\u001B[39m_next, curr(buffer_result))\n\u001B[0;32m     19\u001B[0m \u001B[38;5;66;03m# propagate\u001B[39;00m\n\u001B[1;32m---> 20\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m propagate(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mroot, x)\n",
      "Cell \u001B[1;32mIn[6], line 18\u001B[0m, in \u001B[0;36mANN.__call__.<locals>.propagate\u001B[1;34m(curr, buffer_result)\u001B[0m\n\u001B[0;32m     16\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpropagate\u001B[39m(curr, buffer_result):\n\u001B[0;32m     17\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m curr\u001B[38;5;241m.\u001B[39m_next \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m: \u001B[38;5;28;01mreturn\u001B[39;00m curr(buffer_result)\n\u001B[1;32m---> 18\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m propagate(curr\u001B[38;5;241m.\u001B[39m_next, curr(buffer_result))\n",
      "Cell \u001B[1;32mIn[5], line 17\u001B[0m, in \u001B[0;36mNode.__call__\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m     15\u001B[0m result \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mdot(x, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mweight)\n\u001B[0;32m     16\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutput \u001B[38;5;241m=\u001B[39m result\u001B[38;5;241m.\u001B[39mcopy()\n\u001B[1;32m---> 17\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgrad \u001B[38;5;241m=\u001B[39m gradient(x, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mouput, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mweight, act_func\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mact_func, lr\u001B[38;5;241m=\u001B[39mlr)\n\u001B[0;32m     18\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'Node' object has no attribute 'ouput'"
     ]
    }
   ],
   "source": [
    "model = DNN(len(trainset.x[0]), len(trainset.y[0]))\n",
    "model.loss(trainset)\n",
    "model.train(trainset, iters=1000, lr=0.01)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-05T12:55:31.269689800Z",
     "start_time": "2024-11-05T12:55:30.434685500Z"
    }
   },
   "id": "8c9a12b8e5f113a3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# init a testset\n",
    "index = random.randrange(0, 150)\n",
    "test_x, test_y = testset[index]\n",
    "\n",
    "discrimination = lambda arr, value=1: np.where(arr == value)[0]\n",
    "\n",
    "labels = [\"setosa\",\"versicolour\",\"virginica\"]\n",
    "setosa = np.array([list(trainset.x[_]) for _ in range(trainset.__len__()) if discrimination(trainset.y[_], 1) == 0])\n",
    "versicolour = np.array([list(trainset.x[_]) for _ in range(trainset.__len__()) if discrimination(trainset.y[_], 1) == 1])\n",
    "virginica = np.array([list(trainset.x[_]) for _ in range(trainset.__len__()) if discrimination(trainset.y[_], 1) == 2])\n",
    "pred = model(test_x)\n",
    "\n",
    "fig, ax1 = plt.subplots(1, 1, figsize=(12, 6))\n",
    "ax1.set_xlabel('sepal length')\n",
    "ax1.set_ylabel('petal length')\n",
    "ax1.grid(True, alpha=0.5)\n",
    "\n",
    "ax1.scatter(x=setosa[:, 2], y=setosa[:, 1], s=50, alpha=0.8, c=\"violet\", label=\"setosa\")\n",
    "ax1.scatter(x=versicolour[:, 2], y=versicolour[:, 1], s=50, alpha=0.8, c=\"pink\", label=\"versicolour\")\n",
    "ax1.scatter(x=virginica[:, 2], y=virginica[:, 1], s=50, alpha=0.8, c=\"skyblue\", label=\"virginica\")\n",
    "ax1.scatter(x=test_x[0], y=test_x[1], s=100, alpha=1, c=\"r\", marker=\"+\", label=f\"prediction, '{labels[np.argmax(pred)]}'\")\n",
    "ax1.legend(fontsize=\"10\", loc=\"best\", title=\"Iris Prediction\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-11-05T12:55:31.269689800Z"
    }
   },
   "id": "7c650bcbbd1b14e3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.loss(trainset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-11-05T12:55:31.269689800Z"
    }
   },
   "id": "17ee01703e7de0c1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

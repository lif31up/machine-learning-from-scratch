{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "62db0eaa",
   "metadata": {
    "id": "62db0eaa",
    "ExecuteTime": {
     "end_time": "2025-03-02T03:46:08.962502400Z",
     "start_time": "2025-03-02T03:46:08.911565400Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import plotly.express as px\n",
    "from plotly.offline import iplot\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e66a9cf95b568f9a",
   "metadata": {
    "id": "e66a9cf95b568f9a",
    "ExecuteTime": {
     "end_time": "2025-03-02T03:46:09.080194300Z",
     "start_time": "2025-03-02T03:46:08.920833Z"
    }
   },
   "outputs": [],
   "source": [
    "cancer_set = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "[data sepecification](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html)"
   ],
   "metadata": {
    "collapsed": false,
    "id": "a6c2ddd45323b7e7"
   },
   "id": "a6c2ddd45323b7e7"
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "  def __init__(self, dataset, indices, transform=None, encoder=None):\n",
    "    self.dataset, self.indices = dataset, indices\n",
    "    self.transform, self.encoder = transform, encoder\n",
    "  def __getitem__(self, item: int):\n",
    "    idx = self.indices[item]\n",
    "    feature, label = self.dataset.data[idx], self.dataset.target[idx]\n",
    "    if self.transform: feature = self.transform(feature)\n",
    "    if self.encoder: label = self.encoder(label)\n",
    "    return feature, label\n",
    "  def __len__(self): return len(self.indices)"
   ],
   "metadata": {
    "id": "70149775527c0926",
    "ExecuteTime": {
     "end_time": "2025-03-02T03:46:09.080194300Z",
     "start_time": "2025-03-02T03:46:08.949858400Z"
    }
   },
   "id": "70149775527c0926"
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "indices = random.sample(range(cancer_set.data.__len__()), 100)\n",
    "\n",
    "# init Datasets\n",
    "support_set = Dataset(cancer_set, indices[:50])\n",
    "query_set = Dataset(cancer_set, indices[50:])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-02T03:46:09.083198500Z",
     "start_time": "2025-03-02T03:46:08.962502400Z"
    }
   },
   "id": "86d0143c5032166d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Loss Functions: MSE and MAE\n",
    "\n",
    "Loss functions are a critical component in machine learning models, particularly for regression tasks. They quantify the difference between the predicted values and the actual target values, guiding the optimization process to minimize this error.\n",
    "\n",
    "#### Mean Squared Error (MSE)\n",
    "MSE calculates the average of the squared differences between the predicted and actual values. It is defined as:\n",
    "\n",
    "$$\\text{MSE} = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2$$\n",
    "\n",
    "- **Penalizes larger errors more heavily**: Squaring the errors makes MSE more sensitive to outliers.\n",
    "- **Continuous optimization**: Smooth gradients make it suitable for many gradient-based optimization algorithms.\n",
    "- **Use Case**: Ideal when large errors need to be penalized significantly.\n",
    "\n",
    "### Mean Absolute Error (MAE)\n",
    "MAE calculates the average of the absolute differences between the predicted and actual values. It is defined as:\n",
    "$$\\text{MAE} = \\frac{1}{n} \\sum_{i=1}^{n} |y_i - \\hat{y}_i|$$\n",
    "\n",
    "- **Treats all errors equally**: MAE is less sensitive to outliers compared to MSE.\n",
    "- **Robust to Outliers**: Does not disproportionately penalize larger deviations.\n",
    "- **Use Case**: Ideal for datasets where outliers are present and need to be treated equally."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8bb53511f8beff0"
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "# define loss functions(MSE, MAE)\n",
    "def mean_squared_error(independent, dependent, weight):\n",
    "  probability = np.dot(independent, weight)\n",
    "  return np.mean((probability - dependent) ** 2)\n",
    "# mean_squared_error\n",
    "\n",
    "def mean_absolute_error(independent, dependent, weight):\n",
    "  probability = np.dot(independent, weight)\n",
    "  return np.mean(abs(probability - dependent))\n",
    "# mean_absolute_error"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-02T03:46:09.083198500Z",
     "start_time": "2025-03-02T03:46:08.972360300Z"
    }
   },
   "id": "e4f58cfa6f4638e2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Gradient Descent with Regularization (GDR)\n",
    "Gradient Descent with Regularization (GDR) is an optimization technique used to minimize the loss function while controlling the complexity of the model. By incorporating regularization terms into the loss function, GDR helps to prevent overfitting and improves the generalization of the model to unseen data. Update rule:\n",
    "$$\\theta = \\theta - \\eta \\cdot \\nabla L(\\theta)$$\n",
    "Gradient Descent is an iterative optimization algorithm used to minimize the loss function by updating model parameters in the direction of the steepest descent of the gradient."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2147ee2fd53ec698"
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8e431387",
   "metadata": {
    "id": "8e431387",
    "ExecuteTime": {
     "end_time": "2025-03-02T03:46:09.083198500Z",
     "start_time": "2025-03-02T03:46:08.982986600Z"
    }
   },
   "outputs": [],
   "source": [
    "def sigmoid(x): return 1 / (1 + np.exp(-1 * np.clip(x, -1e2, 1e2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "  def __init__(self, n_inpt): self.weight = np.zeros(shape=(n_inpt))\n",
    "  def gdr(self, x, y, lr):\n",
    "    indications = self.forward(x)\n",
    "    self.weight -= (lr / x.shape[0]) * np.dot(x.T, (indications - y))\n",
    "  # gdr\n",
    "  def train(self, dataset, iters: int, lr=0.01):\n",
    "    for _ in range(iters):\n",
    "      for feature, label in dataset: self.gdr(feature, label, lr=lr)\n",
    "  # train\n",
    "  def forward(self, x): return sigmoid(np.dot(x, self.weight))\n",
    "# LogisticRegression"
   ],
   "metadata": {
    "id": "9ac7d18d7d81de70",
    "ExecuteTime": {
     "end_time": "2025-03-02T03:46:09.104472400Z",
     "start_time": "2025-03-02T03:46:09.000456400Z"
    }
   },
   "id": "9ac7d18d7d81de70"
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "def GDR(model, lr):\n",
    "  def _GDR(x, y):\n",
    "    pred = model.forward(x)\n",
    "    model.weight -= lr * np.dot(x.T, (pred - y))\n",
    "  return _GDR"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-02T03:46:09.104472400Z",
     "start_time": "2025-03-02T03:46:09.012918100Z"
    }
   },
   "id": "8c53a21fd55ef77d"
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f2becd52",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f2becd52",
    "outputId": "92b1e3ad-635d-4d1f-b3c2-e8f963ddea59",
    "ExecuteTime": {
     "end_time": "2025-03-02T03:46:09.738912700Z",
     "start_time": "2025-03-02T03:46:09.026954500Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 148.86it/s, loss=1.66e+6]\n"
     ]
    }
   ],
   "source": [
    "progress_bar = tqdm(range(100))\n",
    "\n",
    "# init and train a model\n",
    "model = LogisticRegression(30)\n",
    "optimizer = GDR(model, 0.001)\n",
    "for _ in progress_bar:\n",
    "  loss = 0.\n",
    "  for feature, label in support_set:\n",
    "    optimizer(feature, label)\n",
    "    loss += mean_squared_error(feature, label, model.weight)\n",
    "  progress_bar.set_postfix(loss=loss/len(support_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4f4b9b467cabc899",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 579
    },
    "id": "4f4b9b467cabc899",
    "outputId": "5432aa6b-fd41-487b-e3d3-11bfbc4ee991",
    "ExecuteTime": {
     "end_time": "2025-03-02T03:46:09.739947500Z",
     "start_time": "2025-03-02T03:46:09.715890900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.94(47/50)\n"
     ]
    }
   ],
   "source": [
    "count, n_samples = 0, len(query_set)\n",
    "for feature, label in support_set:\n",
    "  pred = model.forward(feature)\n",
    "  if round(pred) == label: count += 1\n",
    "print(f\"accuracy: {count / n_samples:.2f}({count}/{n_samples})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
